{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"breast_cancer_classification_trainer.ipynb","version":"0.3.2","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"Xwx9sEtBJp3U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4c41560d-b10c-4f7b-92cc-ac9b118a4b3a","executionInfo":{"status":"ok","timestamp":1566726091787,"user_tz":-180,"elapsed":3019,"user":{"displayName":"Hasan MEN","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBAX85I5vhfX210p3Rj-czTrk9777h-SxKKA1BtnxE=s64","userId":"13924822536646857993"}}},"source":["# import the necessary packages\n","from keras.models import Sequential\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dense\n","from keras import backend as K"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"oYsHZEB_Jp3X","colab_type":"code","colab":{}},"source":["class LeNet:\n","\t@staticmethod\n","\tdef build(width, height, depth, classes):\n","\t\t# initialize the model\n","\t\tmodel = Sequential()\n","\t\tinputShape = (height, width, depth)\n"," \n","\t\t# if we are using \"channels first\", update the input shape\n","\t\tif K.image_data_format() == \"channels_first\":\n","\t\t\tinputShape = (depth, height, width)\n","            \n","\t\t# first set of CONV => RELU => POOL layers\n","\t\tmodel.add(Conv2D(20, (5, 5), padding=\"same\",\n","\t\t\tinput_shape=inputShape))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","        \n","        # second set of CONV => RELU => POOL layers\n","\t\tmodel.add(Conv2D(50, (5, 5), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","        \n","        # first (and only) set of FC => RELU layers\n","\t\tmodel.add(Flatten())\n","\t\tmodel.add(Dense(500))\n","\t\tmodel.add(Activation(\"relu\"))\n"," \n","\t\t# softmax classifier\n","\t\tmodel.add(Dense(classes))\n","\t\tmodel.add(Activation(\"softmax\"))\n"," \n","\t\t# return the constructed network architecture\n","\t\treturn model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hfKyqXgFJp3a","colab_type":"code","colab":{}},"source":["# set the matplotlib backend so figures can be saved in the background\n","import matplotlib\n","matplotlib.use(\"Agg\")\n"," \n","# import the necessary packages\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.image import img_to_array\n","from keras.utils import to_categorical\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import argparse\n","import random\n","import cv2\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tsa-AKa5Jp3d","colab_type":"code","colab":{},"outputId":"2c11531f-9126-4e9e-d1ff-360a95e505a7"},"source":["# initialize the number of epochs to train for, initial learning rate,\n","# and batch size\n","EPOCHS = 25\n","INIT_LR = 1e-3\n","BS = 32\n"," \n","# initialize the data and labels\n","print(\"[INFO] loading images...\")\n","data = []\n","labels = []\n","\n","datasetfolder=\"mass_training_image_png\"\n"," \n","# grab the image paths and randomly shuffle them\n","imagePaths = sorted(list(paths.list_images(datasetfolder)))\n","random.seed(42)\n","random.shuffle(imagePaths)\n","#print(imagePaths)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] loading images...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3gioi8ClJp3f","colab_type":"code","colab":{},"outputId":"686d2c8e-d584-4321-9d11-04687cba24f0"},"source":["# loop over the input images\n","for imagePath in imagePaths:\n","    # load the image, pre-process it, and store it in the data list\n","    image = cv2.imread(imagePath)\n","    image = cv2.resize(image, (28, 28))\n","    image = img_to_array(image)\n","    data.append(image)\n","\n","    # extract the class label from the image path and update the\n","    # labels list\n","    label = imagePath.split(os.path.sep)[-1]\n","    label = 1 if \"MLO\" in label else 0\n","    labels.append(label)\n","labels"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"psj4iSn-Jp3h","colab_type":"code","colab":{},"outputId":"03348601-d20a-4fb1-bee1-8a66179cce08"},"source":["print(\"Found\", len(data), \" image\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 584  image\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-KgK39B8Jp3j","colab_type":"code","colab":{}},"source":["# scale the raw pixel intensities to the range [0, 1]\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n"," \n","# partition the data into training and testing splits using 75% of\n","# the data for training and the remaining 25% for testing\n","(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n"," \n","# convert the labels from integers to vectors\n","trainY = to_categorical(trainY, num_classes=2)\n","testY = to_categorical(testY, num_classes=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fk0hVUe1Jp3l","colab_type":"code","colab":{}},"source":["# construct the image generator for data augmentation\n","aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n","\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n","\thorizontal_flip=True, fill_mode=\"nearest\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fpHM30jVJp3m","colab_type":"code","colab":{},"outputId":"47445e33-5688-4ba2-e704-6b76cc008618"},"source":["# initialize the model\n","print(\"[INFO] compiling model...\")\n","model = LeNet.build(width=28, height=28, depth=3, classes=2)\n","opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n","\tmetrics=[\"accuracy\"])\n"," \n","# train the network\n","print(\"[INFO] training network...\")\n","H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n","\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n","\tepochs=EPOCHS, verbose=1)\n"," \n","# save the model to disk\n","print(\"[INFO] serializing network...\")\n","model.save(\"breast_cancer_classification.model\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] compiling model...\n","[INFO] training network...\n","Epoch 1/25\n","13/13 [==============================] - 1s 77ms/step - loss: 0.5784 - acc: 0.7042 - val_loss: 0.1934 - val_acc: 0.9658\n","Epoch 2/25\n","13/13 [==============================] - 1s 47ms/step - loss: 0.4235 - acc: 0.8218 - val_loss: 0.1498 - val_acc: 0.9726\n","Epoch 3/25\n","13/13 [==============================] - 1s 47ms/step - loss: 0.3286 - acc: 0.8683 - val_loss: 0.0986 - val_acc: 0.9726\n","Epoch 4/25\n","13/13 [==============================] - 1s 48ms/step - loss: 0.2719 - acc: 0.9087 - val_loss: 0.0868 - val_acc: 0.9795\n","Epoch 5/25\n","13/13 [==============================] - 1s 56ms/step - loss: 0.2510 - acc: 0.8950 - val_loss: 0.0939 - val_acc: 0.9658\n","Epoch 6/25\n","13/13 [==============================] - 1s 57ms/step - loss: 0.2402 - acc: 0.9038 - val_loss: 0.0490 - val_acc: 0.9863\n","Epoch 7/25\n","13/13 [==============================] - 1s 49ms/step - loss: 0.2308 - acc: 0.9044 - val_loss: 0.0942 - val_acc: 0.9726\n","Epoch 8/25\n","13/13 [==============================] - 1s 47ms/step - loss: 0.2081 - acc: 0.9233 - val_loss: 0.0674 - val_acc: 0.9795\n","Epoch 9/25\n","13/13 [==============================] - 1s 47ms/step - loss: 0.1653 - acc: 0.9366 - val_loss: 0.0403 - val_acc: 0.9932\n","Epoch 10/25\n","13/13 [==============================] - 1s 47ms/step - loss: 0.2065 - acc: 0.9351 - val_loss: 0.0606 - val_acc: 0.9795\n","Epoch 11/25\n","13/13 [==============================] - 1s 47ms/step - loss: 0.1817 - acc: 0.9294 - val_loss: 0.0359 - val_acc: 0.9863\n","Epoch 12/25\n","13/13 [==============================] - 1s 51ms/step - loss: 0.2014 - acc: 0.9303 - val_loss: 0.0636 - val_acc: 0.9932\n","Epoch 13/25\n","13/13 [==============================] - 1s 52ms/step - loss: 0.1752 - acc: 0.9326 - val_loss: 0.0649 - val_acc: 0.9726\n","Epoch 14/25\n","13/13 [==============================] - 1s 46ms/step - loss: 0.2146 - acc: 0.9193 - val_loss: 0.0573 - val_acc: 0.9863\n","Epoch 15/25\n","13/13 [==============================] - 1s 54ms/step - loss: 0.1120 - acc: 0.9556 - val_loss: 0.0334 - val_acc: 0.9863\n","Epoch 16/25\n","13/13 [==============================] - 1s 64ms/step - loss: 0.1958 - acc: 0.9229 - val_loss: 0.0445 - val_acc: 0.9863\n","Epoch 17/25\n","13/13 [==============================] - 1s 48ms/step - loss: 0.2529 - acc: 0.9106 - val_loss: 0.0614 - val_acc: 0.9726\n","Epoch 18/25\n","13/13 [==============================] - 1s 49ms/step - loss: 0.1976 - acc: 0.9267 - val_loss: 0.0602 - val_acc: 0.9795\n","Epoch 19/25\n","13/13 [==============================] - 1s 55ms/step - loss: 0.1528 - acc: 0.9330 - val_loss: 0.0319 - val_acc: 0.9932\n","Epoch 20/25\n","13/13 [==============================] - 1s 48ms/step - loss: 0.1513 - acc: 0.9498 - val_loss: 0.0581 - val_acc: 0.9726\n","Epoch 21/25\n","13/13 [==============================] - 1s 50ms/step - loss: 0.1360 - acc: 0.9471 - val_loss: 0.0577 - val_acc: 0.9863\n","Epoch 22/25\n","13/13 [==============================] - 1s 51ms/step - loss: 0.1319 - acc: 0.9594 - val_loss: 0.0371 - val_acc: 0.9863\n","Epoch 23/25\n","13/13 [==============================] - 1s 64ms/step - loss: 0.1463 - acc: 0.9518 - val_loss: 0.0783 - val_acc: 0.9863\n","Epoch 24/25\n","13/13 [==============================] - 1s 67ms/step - loss: 0.1511 - acc: 0.9439 - val_loss: 0.0340 - val_acc: 0.9863\n","Epoch 25/25\n","13/13 [==============================] - 1s 55ms/step - loss: 0.1497 - acc: 0.9495 - val_loss: 0.0554 - val_acc: 0.9795\n","[INFO] serializing network...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZgNT_v1FJp3q","colab_type":"code","colab":{},"outputId":"d483995b-7cf6-4712-8c48-49a6552499e9"},"source":["# plot the training loss and accuracy\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","N = EPOCHS\n","plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n","plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy on Santa/Not Santa\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend(loc=\"lower left\")\n","#plt.savefig(\"figure\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x142c22650>"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"QGPf4DwTJp3s","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}